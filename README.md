# Multi-Agent Reinforcement Learning for Coordinated Bipedal Robotics

[![Build Status](https://github.com/EvanJayChou/marl_robotics/workflows/CI/badge.svg)](https://github.com/EvanJayChou/marl_robotics/actions)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Isaac Sim](https://img.shields.io/badge/Isaac-Sim-76B900?logo=nvidia&logoColor=white)](https://developer.nvidia.com/isaac/sim)
[![ROS 2 Humble](https://img.shields.io/badge/ROS%202-Humble-blue.svg)](https://docs.ros.org/en/humble/)

## ğŸš€ Quick Start
[Installation instructions, demo video, key features]

## ğŸ“– Documentation
[Links to detailed documentation]

## ğŸ¯ Project Overview

This research project investigates the use of simulative environments and large-scale deep reinforcement learning to train and optimize agents for bipedal locomotion and robotic movement/perception.

### Key Components

- Deep reinforcement learning within large-scale simulative environments
- Coordinated bipedal locomotion through multi-agent autonomy
- Sim2Real transfer and integration in preparation for real-world use

### Software Specifications

- NVIDIA Isaac Sim
- Linux: Ubuntu 22.04 (WSL 2)
- Stable Baselines3
- CUDA Toolkit

## ğŸ—ï¸ Architecture
[System architecture diagram and explanation]

## ğŸ“Š Results
[Key results, performance metrics, comparison tables]

## ğŸ¤ Contributing
[Contribution guidelines]

## Credits

Developed by Evan Chou

*Inspired by Disney Research's BDX Droids*
